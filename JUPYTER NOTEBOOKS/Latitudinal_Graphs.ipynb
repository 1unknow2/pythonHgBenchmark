{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xbpch\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib import colorbar, colors\n",
    "import statistics\n",
    "from sklearn.metrics import r2_score\n",
    "from SiteLevels import levels\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LatitudinalGraphs(Dataset_OLD, Dataset_NEW):\n",
    "    \"\"\"Plot observations against the model for different latitudes  (Southern Mid Latitiude, North Mid Latitude,\n",
    "    Arctic, Antarctic).\n",
    "    \n",
    "    Args:\n",
    "    Dataset_OLD (str) : Reference model bpch file\n",
    "    Dataset_NEW (str) : New model bpch file\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Import the observed data from the sites     \n",
    "    Hgobs = pd.read_csv('data/TGMSiteMonthly.csv',  skiprows=[0], na_values=(-9999))\n",
    "    Hgobs.columns=['SiteID', 'Lat', 'Lon','Month', 'Year', 'Concentration', 'Standard deviation']\n",
    " \n",
    "\n",
    "\n",
    "    # Make a variable for the unit conversion factor to obtain ng/m^3\n",
    "    Unit_Conversion= 8.93\n",
    "    # Make arrays of SiteIDs for the Arctic, Antarctic and Northern and Souther Mid Latitudes.\n",
    "    Arctic=['ALT', 'VRS', 'ZEP', 'AND', 'PAL','AMD']\n",
    "    Arctic = [e for e in Arctic if e in list(Hgobs.SiteID)]\n",
    "    \n",
    "    SouthMidLat=['CPT', 'AMS', 'BAR']\n",
    "    SouthMidLat = [e for e in SouthMidLat if e in list(Hgobs.SiteID)]\n",
    "    \n",
    "    Antarctic= ['TRO', 'DDU', 'DMC']\n",
    "    Antarctic = [e for e in Antarctic if e in list(Hgobs.SiteID)]\n",
    "    \n",
    "    NorthMidLat= ['MHD', 'UDH', 'KEJ',  'HTW', 'PNY', 'ATN', 'YKV', 'GRB','BIR', 'WAL', 'BRA', 'SAT', 'THOMPFARM', 'SCO', 'STIWELL', 'EBG'] \n",
    "    NorthMidLat = [e for e in NorthMidLat if e in list(Hgobs.SiteID)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create numpy zeros for the amount of items in each list.\n",
    "    Arc_ds=np.zeros(len(Arctic))\n",
    "    SML_ds=np.zeros(len(SouthMidLat))\n",
    "    Ant_ds=np.zeros(len(Antarctic))\n",
    "    NML_ds= np.zeros(len(NorthMidLat))\n",
    "\n",
    "\n",
    "    # Select the list of numpy zeros for the Arctic and extract the data from each site, creating a new data.\n",
    "    for i in range (len(Arctic)):\n",
    "       \n",
    "\n",
    "        Arc_ds= Hgobs[Hgobs.SiteID==Arctic[i]].reset_index()\n",
    "   \n",
    "        if i==0:\n",
    "\n",
    "            All_Arctic_ds = Arc_ds\n",
    "\n",
    "        else:\n",
    "\n",
    "            All_Arctic_ds = pd.concat([All_Arctic_ds,Arc_ds])\n",
    "\n",
    "    # Calculate the mean and stanadard deviation for each month.\n",
    "    Arc_graph = All_Arctic_ds.groupby('Month').mean()\n",
    "    Arc_graph_SD = All_Arctic_ds.groupby('Month').std() \n",
    "    # Select all unique latitudes and longitudes from the dataset.\n",
    "    Arc_lat= All_Arctic_ds.Lat.unique()\n",
    "    Arc_lon= All_Arctic_ds.Lon.unique()\n",
    "\n",
    "    # Create a dataset for the total TGM at each site for the reference and new models.\n",
    "    for i in range (len(Arctic)): \n",
    "        Arc_OLD_Hg0 =((Dataset_OLD['IJ_AVG_S_Hg0'].isel(lev=levels(Arctic[i]) ) * Unit_Conversion))                              \n",
    "        Arc_OLD_Hg2 =((Dataset_OLD['IJ_AVG_S_Hg2'].isel(lev=levels(Arctic[i])) * Unit_Conversion) )               \n",
    "        Arc_TGM_Old = (Arc_OLD_Hg0 + Arc_OLD_Hg2)\n",
    "        Arc_OLD_mod= (Arc_TGM_Old.sel(lat=Arc_lat[i], lon=Arc_lon[i],  method='nearest'))\n",
    "    \n",
    "        Arc_NEW_Hg0 =((Dataset_NEW['IJ_AVG_S_Hg0'].isel(lev=levels(Arctic[i]) )) * Unit_Conversion)\n",
    "        Arc_NEW_Hg2 =((Dataset_NEW['IJ_AVG_S_Hg2'].isel(lev=levels(Arctic[i]) )) * Unit_Conversion)\n",
    "        Arc_TGM_New =( Arc_NEW_Hg0 + Arc_NEW_Hg2)\n",
    "        Arc_NEW_mod= (Arc_TGM_New.sel(lat=Arc_lat[i], lon=Arc_lon[i],  method='nearest'))\n",
    "        if i==0:\n",
    "\n",
    "            Arc_DS_OLD = Arc_OLD_mod\n",
    "            Arc_DS_NEW = Arc_NEW_mod\n",
    "        else:\n",
    "\n",
    "            Arc_DS_OLD= xr.concat([Arc_DS_OLD,Arc_OLD_mod])\n",
    "            Arc_DS_NEW= xr.concat([Arc_DS_NEW,Arc_NEW_mod])\n",
    "   # Calculate the mean and standard deviations for the reference and new models.\n",
    "    Arc_meanmod_OLD=Arc_DS_OLD.mean('concat_dims')\n",
    "    Arc_stdevmod_OLD= Arc_DS_OLD.std('concat_dims')\n",
    "    \n",
    "    Arc_meanmod_NEW= Arc_DS_NEW.mean('concat_dims')\n",
    "    Arc_stdevmod_NEW= Arc_DS_NEW.std('concat_dims')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    # Select the list of numpy zeros for the South Mid Latitudes and extract the data from each site, creating a\n",
    "    # new data.\n",
    "    for i in range (len(SouthMidLat)):\n",
    "        SML_ds= Hgobs[Hgobs.SiteID==SouthMidLat[i]].reset_index()\n",
    "        if i==0:\n",
    "\n",
    "            All_SML_ds = SML_ds\n",
    "\n",
    "        else:\n",
    "\n",
    "            All_SML_ds = pd.concat([All_SML_ds,SML_ds])\n",
    "        \n",
    "    # Calculate the mean and stanadard deviation for each month.        \n",
    "    SML_graph = All_SML_ds.groupby('Month').mean()\n",
    "    SML_graph_SD = All_SML_ds.groupby('Month').std()\n",
    "    # Select all unique latitudes and longitudes from the dataset.\n",
    "    SML_lat= All_SML_ds.Lat.unique()\n",
    "    SML_lon= All_SML_ds.Lon.unique()\n",
    "    \n",
    "    # Create a dataset for the total TGM at each site for the reference and new models.    \n",
    "    for i in range (len(SouthMidLat)): \n",
    "        SML_OLD_Hg0 =((Dataset_OLD['IJ_AVG_S_Hg0'].isel(lev=levels(SouthMidLat[i]) ) * Unit_Conversion))                              \n",
    "        SML_OLD_Hg2 =((Dataset_OLD['IJ_AVG_S_Hg2'].isel(lev=levels(SouthMidLat[i])) * Unit_Conversion) )               \n",
    "        SML_TGM_Old = (SML_OLD_Hg0 + SML_OLD_Hg2)\n",
    "        SML_OLD_mod= (SML_TGM_Old.sel(lat=SML_lat[i], lon=SML_lon[i],  method='nearest'))\n",
    "    \n",
    "        SML_NEW_Hg0 =((Dataset_NEW['IJ_AVG_S_Hg0'].isel(lev=levels(SouthMidLat[i]) )) * Unit_Conversion)\n",
    "        SML_NEW_Hg2 =((Dataset_NEW['IJ_AVG_S_Hg2'].isel(lev=levels(SouthMidLat[i]) )) * Unit_Conversion)\n",
    "        SML_TGM_New =( SML_NEW_Hg0 + SML_NEW_Hg2)\n",
    "        SML_NEW_mod= (SML_TGM_New.sel(lat=SML_lat[i], lon=SML_lon[i],  method='nearest'))\n",
    "        if i==0:\n",
    "\n",
    "            SML_DS_OLD = SML_OLD_mod\n",
    "           # TGM_New_Arc= TGM_New\n",
    "            SML_DS_NEW = SML_NEW_mod\n",
    "        else:\n",
    "\n",
    "            SML_DS_OLD= xr.concat([SML_DS_OLD,SML_OLD_mod])\n",
    "            SML_DS_NEW= xr.concat([SML_DS_NEW,SML_NEW_mod])\n",
    "    # Calculate the mean and standard deviations for the reference and new models.\n",
    "    SML_meanmod_OLD=SML_DS_OLD.mean('concat_dims')\n",
    "    SML_stdevmod_OLD= SML_DS_OLD.std('concat_dims')\n",
    "    \n",
    "    SML_meanmod_NEW= SML_DS_NEW.mean('concat_dims')\n",
    "    SML_stdevmod_NEW= SML_DS_NEW.std('concat_dims')  \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    # Select the list of numpy zeros for the Antarctic and extract the data from each site, creating a new data.    \n",
    "    for i in range (len(Antarctic)):\n",
    "        Ant_ds= Hgobs[Hgobs.SiteID==Antarctic[i]].reset_index()\n",
    "        if i==0:\n",
    "\n",
    "            All_Ant_ds = Ant_ds\n",
    "\n",
    "        else:\n",
    "\n",
    "            All_Ant_ds = pd.concat([All_Ant_ds,Ant_ds])    \n",
    "    \n",
    "    # Calculate the mean and stanadard deviation for each month.        \n",
    "    Ant_graph = All_Ant_ds.groupby('Month').mean()\n",
    "    Ant_graph_SD = All_Ant_ds.groupby('Month').std()\n",
    "    # Select all unique latitudes and longitudes from the dataset.\n",
    "    Ant_lat= All_Ant_ds.Lat.unique()\n",
    "    Ant_lon= All_Ant_ds.Lon.unique()\n",
    "    \n",
    "    # Create a dataset for the total TGM at each site for the reference and new models.\n",
    "    for i in range (len(Antarctic)): \n",
    "        Ant_OLD_Hg0 =((Dataset_OLD['IJ_AVG_S_Hg0'].isel(lev=levels(Antarctic[i]) ) * Unit_Conversion))                              \n",
    "        Ant_OLD_Hg2 =((Dataset_OLD['IJ_AVG_S_Hg2'].isel(lev=levels(Antarctic[i])) * Unit_Conversion) )               \n",
    "        Ant_TGM_Old = (Ant_OLD_Hg0 + Ant_OLD_Hg2)\n",
    "        Ant_OLD_mod= (Ant_TGM_Old.sel(lat=Ant_lat[i], lon=Ant_lon[i],  method='nearest'))\n",
    "    \n",
    "        Ant_NEW_Hg0 =((Dataset_NEW['IJ_AVG_S_Hg0'].isel(lev=levels(Antarctic[i]) )) * Unit_Conversion)\n",
    "        Ant_NEW_Hg2 =((Dataset_NEW['IJ_AVG_S_Hg2'].isel(lev=levels(Antarctic[i]) )) * Unit_Conversion)\n",
    "        Ant_TGM_New =( Ant_NEW_Hg0 + Ant_NEW_Hg2)\n",
    "        Ant_NEW_mod= (Ant_TGM_New.sel(lat=Ant_lat[i], lon=Ant_lon[i],  method='nearest'))\n",
    "        if i==0:\n",
    "\n",
    "            Ant_DS_OLD = Ant_OLD_mod\n",
    "           # TGM_New_Arc= TGM_New\n",
    "            Ant_DS_NEW = Ant_NEW_mod\n",
    "        else:\n",
    "\n",
    "            Ant_DS_OLD= xr.concat([Ant_DS_OLD,Ant_OLD_mod])\n",
    "            Ant_DS_NEW= xr.concat([Ant_DS_NEW,Ant_NEW_mod])\n",
    "            \n",
    "    # Calculate the mean and standard deviations for the reference and new models.   \n",
    "    Ant_meanmod_OLD=Ant_DS_OLD.mean('concat_dims')\n",
    "    Ant_stdevmod_OLD= Ant_DS_OLD.std('concat_dims')\n",
    "    \n",
    "    Ant_meanmod_NEW= Ant_DS_NEW.mean('concat_dims')\n",
    "    Ant_stdevmod_NEW= Ant_DS_NEW.std('concat_dims')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Select the list of numpy zeros for the North Mid Latitudes and extract the data from each site, creating a\n",
    "    # new data.\n",
    "    for i in range (len(NorthMidLat)):\n",
    "        NML_ds= Hgobs[Hgobs.SiteID==NorthMidLat[i]].reset_index()\n",
    "        if i==0:\n",
    "\n",
    "            All_NML_ds = NML_ds\n",
    "\n",
    "        else:\n",
    "\n",
    "            All_NML_ds = pd.concat([All_NML_ds,NML_ds])\n",
    "\n",
    "    \n",
    "    # Calculate the mean and stanadard deviation for each month.        \n",
    "    NML_graph = All_NML_ds.groupby('Month').mean()\n",
    "    NML_graph_SD = All_NML_ds.groupby('Month').std()\n",
    "    # Select all unique latitudes and longitudes from the dataset.\n",
    "    NML_lat= All_NML_ds.Lat.unique()\n",
    "    NML_lon= All_NML_ds.Lon.unique()\n",
    "    \n",
    "    # Create a dataset for the total TGM at each site for the reference and new models.    \n",
    "    for i in range (len(NorthMidLat)): \n",
    "        NML_OLD_Hg0 =((Dataset_OLD['IJ_AVG_S_Hg0'].isel(lev=levels(NorthMidLat[i]) ) * Unit_Conversion))                              \n",
    "        NML_OLD_Hg2 =((Dataset_OLD['IJ_AVG_S_Hg2'].isel(lev=levels(NorthMidLat[i])) * Unit_Conversion) )               \n",
    "        NML_TGM_Old = (NML_OLD_Hg0 + NML_OLD_Hg2)\n",
    "        NML_OLD_mod= (NML_TGM_Old.sel(lat=NML_lat[i], lon=NML_lon[i],  method='nearest'))\n",
    "    \n",
    "        NML_NEW_Hg0 =((Dataset_NEW['IJ_AVG_S_Hg0'].isel(lev=levels(NorthMidLat[i]) )) * Unit_Conversion)\n",
    "        NML_NEW_Hg2 =((Dataset_NEW['IJ_AVG_S_Hg2'].isel(lev=levels(NorthMidLat[i]) )) * Unit_Conversion)\n",
    "        NML_TGM_New =( NML_NEW_Hg0 + NML_NEW_Hg2)\n",
    "        NML_NEW_mod= (NML_TGM_New.sel(lat=NML_lat[i], lon=NML_lon[i],  method='nearest'))\n",
    "        if i==0:\n",
    "\n",
    "            NML_DS_OLD = NML_OLD_mod\n",
    "           # TGM_New_Arc= TGM_New\n",
    "            NML_DS_NEW = NML_NEW_mod\n",
    "        else:\n",
    "\n",
    "            NML_DS_OLD= xr.concat([NML_DS_OLD,NML_OLD_mod])\n",
    "            NML_DS_NEW= xr.concat([NML_DS_NEW,NML_NEW_mod])\n",
    "            \n",
    "    # Calculate the mean and standard deviations for the reference and new models.\n",
    "    NML_meanmod_OLD=NML_DS_OLD.mean('concat_dims')\n",
    "    NML_stdevmod_OLD= NML_DS_OLD.std('concat_dims')\n",
    "    \n",
    "    NML_meanmod_NEW= NML_DS_NEW.mean('concat_dims')\n",
    "    NML_stdevmod_NEW= NML_DS_NEW.std('concat_dims')\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # Plot the four graphs as subplots.\n",
    "    plt.figure(figsize=(20,10))\n",
    "    \n",
    "                                                # ARCTIC #\n",
    "    # Convert the time data from a float to a string, specifying months for graph labels\n",
    "    Arc_ds.index=pd.to_datetime(Arc_ds.Month, format='%m')\n",
    "    # Add a subplot\n",
    "    ax= plt.subplot(221)\n",
    "    # Plot the observations and their error.\n",
    "    plt.errorbar(Arc_ds.Month, Arc_graph.Concentration,yerr=Arc_graph_SD.Concentration, color='k')\n",
    "    # Plot the reference and new models on the same graph with their errors.\n",
    "    ax.errorbar(Arc_ds.Month,Arc_meanmod_OLD ,yerr=Arc_stdevmod_OLD, color='Blue')\n",
    "    ax.errorbar(Arc_ds.Month, Arc_meanmod_NEW,yerr=Arc_stdevmod_NEW, color='Red')\n",
    "    # Label the x and y axis. \n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('TGM (ng/m3)')\n",
    "    # Add a legend\n",
    "    plt.legend([ 'Observations','Reference Model','New Model' ])\n",
    "    # Add a title.\n",
    "    plt.title(\"Arctic\")\n",
    "    # Set ticks to every month \n",
    "    ax.set_xticks(Arc_ds.Month)\n",
    "    # Set tick labels to month names\n",
    "    ax.set_xticklabels(Arc_ds.index.strftime('%b'))\n",
    "    \n",
    "                                                # ANTARCTIC #    \n",
    "    # Convert the time data from a float to a string, specifying months for graph labels\n",
    "    Ant_ds.index=pd.to_datetime(Ant_ds.Month, format='%m')    \n",
    "    # Add a subplot.\n",
    "    ax= plt.subplot(222)\n",
    "    # Plot the observations and their error.\n",
    "    plt.errorbar(Ant_ds.Month, Ant_graph.Concentration,yerr=Ant_graph_SD.Concentration, color='k')\n",
    "    # Plot the reference and new models on the same graph with their errors.\n",
    "    ax.errorbar(Ant_ds.Month,Ant_meanmod_OLD ,yerr=Ant_stdevmod_OLD, color='Blue')\n",
    "    ax.errorbar(Ant_ds.Month, Ant_meanmod_NEW,yerr=Ant_stdevmod_NEW, color='Red')\n",
    "    # Label the x and y axis. \n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('TGM (ng/m3)')\n",
    "    # Add a legend    \n",
    "    plt.legend([ 'Observations','Reference Model','New Model' ])\n",
    "    # Add a title.\n",
    "    plt.title(\"Antarctic\")\n",
    "    # Set ticks to every month \n",
    "    ax.set_xticks(Ant_ds.Month)    \n",
    "    # Set tick labels to month names\n",
    "    ax.set_xticklabels(Ant_ds.index.strftime('%b'))\n",
    "    \n",
    "    \n",
    "                                        # NORTHERN MID LATITUDES #     \n",
    "    # Convert the time data from a float to a string, specifying months for graph labels\n",
    "    NML_ds.index=pd.to_datetime(NML_ds.Month, format='%m')\n",
    "    # Add a subplot. \n",
    "    ax= plt.subplot(223)\n",
    "    # Plot the observations and their error.\n",
    "    plt.errorbar(NML_ds.Month, NML_graph.Concentration,yerr=NML_graph_SD.Concentration, color='k')\n",
    "    # Plot the reference and new models on the same graph with their errors.\n",
    "    ax.errorbar(NML_ds.Month,NML_meanmod_OLD ,yerr=NML_stdevmod_OLD, color='Blue')\n",
    "    ax.errorbar(NML_ds.Month, NML_meanmod_NEW,yerr=NML_stdevmod_NEW, color='Red')\n",
    "    # Label the x and y axis.     \n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('TGM (ng/m3)')\n",
    "    # Add a legend\n",
    "    plt.legend([ 'Observations','Reference Model','New Model' ])\n",
    "    # Add a title.\n",
    "    plt.title(\"Northern Mid Latitudes\")\n",
    "    # Set ticks to every month \n",
    "    ax.set_xticks(NML_ds.Month)\n",
    "    # Set tick labels to month names\n",
    "    ax.set_xticklabels(NML_ds.index.strftime('%b'))\n",
    "    \n",
    "                                        # SOUTHERN MID LATITUDES #     \n",
    "    # Convert the time data from a float to a string, specifying months for graph labels\n",
    "    SML_ds.index=pd.to_datetime(SML_ds.Month, format='%m')\n",
    "    # Add a subplot.\n",
    "    ax= plt.subplot(224)\n",
    "    # Plot the observations and their error.\n",
    "    plt.errorbar(SML_ds.Month, SML_graph.Concentration,yerr=SML_graph_SD.Concentration, color='k')\n",
    "    # Plot the reference and new models on the same graph with their errors.\n",
    "    ax.errorbar(SML_ds.Month,SML_meanmod_OLD ,yerr=SML_stdevmod_OLD, color='Blue')\n",
    "    ax.errorbar(SML_ds.Month, SML_meanmod_NEW,yerr=SML_stdevmod_NEW, color='Red')\n",
    "    # Label the x and y axis. \n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('TGM (ng/m3)')\n",
    "    # Add a legend\n",
    "    plt.legend([ 'Observations','Reference Model','New Model' ])\n",
    "    # Add a title.\n",
    "    plt.title(\"Southern Mid Latitudes\")\n",
    "    # Set ticks to every month \n",
    "    ax.set_xticks(SML_ds.Month)    \n",
    "    # Set tick labels to month names\n",
    "    ax.set_xticklabels(SML_ds.index.strftime('%b'))\n",
    "  \n",
    "\n",
    "    \n",
    "    \n",
    "     # Show the 4 subplots \n",
    "    LatGraph= plt.show()\n",
    "    return LatGraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
